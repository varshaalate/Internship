{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DIAB_SOL.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Jgr6kgqR3Lq5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"66792bfd-85fe-4f88-f9b5-05a7405c5b09","executionInfo":{"status":"ok","timestamp":1640674339147,"user_tz":-330,"elapsed":24128,"user":{"displayName":"Namrata Chougule","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12211585670245213619"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","77/77 [==============================] - 1s 1ms/step - loss: 1.3799 - accuracy: 0.6458\n","Epoch 2/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.8552 - accuracy: 0.6276\n","Epoch 3/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.8040 - accuracy: 0.6341\n","Epoch 4/150\n","77/77 [==============================] - 0s 998us/step - loss: 0.7160 - accuracy: 0.6367\n","Epoch 5/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.6328\n","Epoch 6/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.6341\n","Epoch 7/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.6549\n","Epoch 8/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.7067 - accuracy: 0.6107\n","Epoch 9/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6549\n","Epoch 10/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6612 - accuracy: 0.6341\n","Epoch 11/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6222 - accuracy: 0.6654\n","Epoch 12/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6353 - accuracy: 0.6432\n","Epoch 13/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.6784\n","Epoch 14/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6221 - accuracy: 0.6628\n","Epoch 15/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6070 - accuracy: 0.6745\n","Epoch 16/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6102 - accuracy: 0.6875\n","Epoch 17/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6081 - accuracy: 0.6888\n","Epoch 18/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5988 - accuracy: 0.6862\n","Epoch 19/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5833 - accuracy: 0.6979\n","Epoch 20/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5931 - accuracy: 0.6953\n","Epoch 21/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5942 - accuracy: 0.6810\n","Epoch 22/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5866 - accuracy: 0.7018\n","Epoch 23/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5863 - accuracy: 0.6849\n","Epoch 24/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5878 - accuracy: 0.6862\n","Epoch 25/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5757 - accuracy: 0.6979\n","Epoch 26/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5940 - accuracy: 0.6979\n","Epoch 27/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.6875\n","Epoch 28/150\n","77/77 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.7161\n","Epoch 29/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7214\n","Epoch 30/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.6953\n","Epoch 31/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5601 - accuracy: 0.7279\n","Epoch 32/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5687 - accuracy: 0.7266\n","Epoch 33/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.7201\n","Epoch 34/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.7070\n","Epoch 35/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7240\n","Epoch 36/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.7253\n","Epoch 37/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5556 - accuracy: 0.7318\n","Epoch 38/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5552 - accuracy: 0.7188\n","Epoch 39/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5811 - accuracy: 0.7018\n","Epoch 40/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7214\n","Epoch 41/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5503 - accuracy: 0.7318\n","Epoch 42/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5533 - accuracy: 0.7305\n","Epoch 43/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5497 - accuracy: 0.7161\n","Epoch 44/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.7240\n","Epoch 45/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.7253\n","Epoch 46/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5460 - accuracy: 0.7344\n","Epoch 47/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.7344\n","Epoch 48/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5470 - accuracy: 0.7227\n","Epoch 49/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5403 - accuracy: 0.7266\n","Epoch 50/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.7318\n","Epoch 51/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5611 - accuracy: 0.7096\n","Epoch 52/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5506 - accuracy: 0.7227\n","Epoch 53/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5518 - accuracy: 0.7266\n","Epoch 54/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5399 - accuracy: 0.7240\n","Epoch 55/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5571 - accuracy: 0.7266\n","Epoch 56/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5431 - accuracy: 0.7370\n","Epoch 57/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.7409\n","Epoch 58/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5385 - accuracy: 0.7448\n","Epoch 59/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5517 - accuracy: 0.7292\n","Epoch 60/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5348 - accuracy: 0.7448\n","Epoch 61/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5389 - accuracy: 0.7292\n","Epoch 62/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.7331\n","Epoch 63/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5363 - accuracy: 0.7565\n","Epoch 64/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.7344\n","Epoch 65/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5409 - accuracy: 0.7357\n","Epoch 66/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.7500\n","Epoch 67/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5316 - accuracy: 0.7357\n","Epoch 68/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.7383\n","Epoch 69/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6006 - accuracy: 0.7031\n","Epoch 70/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.7383\n","Epoch 71/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5282 - accuracy: 0.7331\n","Epoch 72/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5258 - accuracy: 0.7539\n","Epoch 73/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5175 - accuracy: 0.7552\n","Epoch 74/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5189 - accuracy: 0.7474\n","Epoch 75/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.7396\n","Epoch 76/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5230 - accuracy: 0.7604\n","Epoch 77/150\n","77/77 [==============================] - 0s 998us/step - loss: 0.5190 - accuracy: 0.7383\n","Epoch 78/150\n","77/77 [==============================] - 0s 996us/step - loss: 0.5286 - accuracy: 0.7396\n","Epoch 79/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5238 - accuracy: 0.7448\n","Epoch 80/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5335 - accuracy: 0.7422\n","Epoch 81/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5337 - accuracy: 0.7435\n","Epoch 82/150\n","77/77 [==============================] - 0s 994us/step - loss: 0.5221 - accuracy: 0.7461\n","Epoch 83/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5174 - accuracy: 0.7513\n","Epoch 84/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.7474\n","Epoch 85/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5308 - accuracy: 0.7383\n","Epoch 86/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5271 - accuracy: 0.7552\n","Epoch 87/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.7578\n","Epoch 88/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.7669\n","Epoch 89/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5184 - accuracy: 0.7669\n","Epoch 90/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5225 - accuracy: 0.7461\n","Epoch 91/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.7461\n","Epoch 92/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.7565\n","Epoch 93/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5382 - accuracy: 0.7461\n","Epoch 94/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.7578\n","Epoch 95/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5090 - accuracy: 0.7552\n","Epoch 96/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7500\n","Epoch 97/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.7591\n","Epoch 98/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.7539\n","Epoch 99/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5234 - accuracy: 0.7370\n","Epoch 100/150\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7552\n","Epoch 101/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7630\n","Epoch 102/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5156 - accuracy: 0.7513\n","Epoch 103/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.7539\n","Epoch 104/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.7643\n","Epoch 105/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.7734\n","Epoch 106/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7617\n","Epoch 107/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.7552\n","Epoch 108/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.7604\n","Epoch 109/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7708\n","Epoch 110/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.7604\n","Epoch 111/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5155 - accuracy: 0.7513\n","Epoch 112/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.7500\n","Epoch 113/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7682\n","Epoch 114/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7682\n","Epoch 115/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7604\n","Epoch 116/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5115 - accuracy: 0.7513\n","Epoch 117/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7552\n","Epoch 118/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.7565\n","Epoch 119/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7630\n","Epoch 120/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.7552\n","Epoch 121/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.7682\n","Epoch 122/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7474\n","Epoch 123/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7695\n","Epoch 124/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7630\n","Epoch 125/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.7643\n","Epoch 126/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7734\n","Epoch 127/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7461\n","Epoch 128/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.7721\n","Epoch 129/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4997 - accuracy: 0.7617\n","Epoch 130/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.7630\n","Epoch 131/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7630\n","Epoch 132/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7695\n","Epoch 133/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.7799\n","Epoch 134/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.7591\n","Epoch 135/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7656\n","Epoch 136/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5121 - accuracy: 0.7682\n","Epoch 137/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7695\n","Epoch 138/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.7643\n","Epoch 139/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.7760\n","Epoch 140/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7591\n","Epoch 141/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.7734\n","Epoch 142/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.7786\n","Epoch 143/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7682\n","Epoch 144/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.7669\n","Epoch 145/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5112 - accuracy: 0.7500\n","Epoch 146/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.7643\n","Epoch 147/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.7682\n","Epoch 148/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5112 - accuracy: 0.7617\n","Epoch 149/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.7396\n","Epoch 150/150\n","77/77 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7721\n","24/24 [==============================] - 0s 980us/step - loss: 0.4679 - accuracy: 0.7786\n","Model accuracy: 77.86\n"]}],"source":["import pandas as pd\n","data = pd.read_csv('diabetes.csv')\n","x = data.drop(\"Outcome\", axis=1)\n","y = data[\"Outcome\"]\n","from keras.models import Sequential\n","from keras.layers import Dense\n","model = Sequential()\n","model.add(Dense(12, input_dim=8, activation=\"relu\"))\n","model.add(Dense(12, activation=\"relu\"))\n","model.add(Dense(1, activation=\"sigmoid\"))\n","model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","model.fit(x,y, epochs=150, batch_size=10)\n","_, accuracy = model.evaluate(x, y)\n","print(\"Model accuracy: %.2f\"% (accuracy*100))"]},{"cell_type":"code","source":["predictions = model.predict(x)     #make predictions\n","#round the prediction\n","rounded = [round(x[0]) for x in predictions]\n","rounded"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dj5odbxkB_q2","outputId":"33525610-97ec-48a9-87de-ca4f6fe8ea49"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0]"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["https://www.analyticsvidhya.com/blog/2021/05/develop-your-first-deep-learning-model-in-python-with-keras/"],"metadata":{"id":"Um_mnVShCD0z"}},{"cell_type":"code","source":[""],"metadata":{"id":"WIGJ-oK1B_ft"},"execution_count":null,"outputs":[]}]}